{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25962459-9a70-4899-bc18-995ca0ec977c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_data = load_dataset(\"stanfordnlp/imdb\")\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d019ff46-dbea-45fc-a9fd-9d1a8d16537c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worth the entertainment value of a rental, especially if you like action movies. This one features the usual car chases, fights with the great Van Damme kick style, shooting battles with the 40 shell load shotgun, and even terrorist style bombs. All of this is entertaining and competently handled but there is nothing that really blows you away if you've seen your share before.\n",
      "\n",
      "The plot is made interesting by the inclusion of a rabbit, which is clever but hardly profound. Many of the characters are heavily stereotyped -- the angry veterans, the terrified illegal aliens, the crooked cops, the indifferent feds, the bitchy tough lady station head, the crooked politician, the fat federale who looks like he was typecast as the Mexican in a Hollywood movie from the 1940s. All passably acted but again nothing special.\n",
      "\n",
      "I thought the main villains were pretty well done and fairly well acted. By the end of the movie you certainly knew who the good guys were and weren't. There was an emotional lift as the really bad ones got their just deserts. Very simplistic, but then you weren't expecting Hamlet, right? The only thing I found really annoying was the constant cuts to VDs daughter during the last fight scene.\n",
      "\n",
      "Not bad. Not good. Passable 4.\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "re_br = re.compile(r'<br\\s*?/?>')\n",
    "raw_data = raw_data.map(\n",
    "    lambda x: {\"text\": [re_br.sub(\"\\n\", reviews) for reviews in x['text']]},\n",
    "    batched=True\n",
    ")\n",
    "print(raw_data['test'][1]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70f48862-48e3-45ae-99b0-e5d7901d71cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "# from transformers import TrainingArguments\n",
    "\n",
    "\n",
    "output_dir = \"C:/Users/Steven/IMDB/bert-finetuned-imdb-sentiment-accelerate-epoch_3\"\n",
    "config = f\"{output_dir}/config\"\n",
    "model_checkpoint = \"bert-base-uncased\"\n",
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    # config=config, \n",
    "    num_labels=2, \n",
    "    id2label=id2label, \n",
    "    label2id=label2id, \n",
    "    # use_flash_attention_2=False                                        \n",
    "    \n",
    ")\n",
    "# training_args = TrainingArguments(\n",
    "#     per_device_train_batch_size=8,\n",
    "#     fp16=True,\n",
    "#     learning_rate=3e-5,\n",
    "#     output_dir=\"bert-finetuned-imdb-sentiment-accelerate\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59f766dd-5ad7-4840-baf6-77911c3647bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_split(examples):\n",
    "    result = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_overflowing_tokens=True,\n",
    "\n",
    "    )\n",
    "\n",
    "    # # Extract mapping between new and old indices\n",
    "    sample_map = result.pop(\"overflow_to_sample_mapping\")\n",
    "    for _, values in examples.items():\n",
    "        result[\"labels\"] = [values[i] for i in sample_map]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b8b9d4c-d243-4630-aa0b-bb405b39597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# train_data = raw_data['train'].shuffle(seed=42)\n",
    "test_data = raw_data['test'].shuffle(seed=42)\n",
    "# tokenized_train = train_data.map(\n",
    "#     tokenize_and_split, \n",
    "#     batched=True,\n",
    "#     remove_columns=train_data.column_names\n",
    "# )\n",
    "# tokenized_sample.set_format('torch')\n",
    "tokenized_test = test_data.map(\n",
    "    tokenize_and_split, \n",
    "    batched=True,\n",
    "    remove_columns=test_data.column_names\n",
    ")\n",
    "# tokenized_sample_test.set_format('torch')\n",
    "# train_dataloader = DataLoader(\n",
    "#     tokenized_train,\n",
    "#     shuffle=True,\n",
    "#     batch_size=8,\n",
    "#     collate_fn=data_collator\n",
    "# )\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_test,\n",
    "    batch_size=8,\n",
    "    collate_fn=data_collator,\n",
    "    pin_memory=True,\n",
    "    pin_memory_device='cuda:0'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b1503bc-ba83-488d-81c6-eb7bc626624a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae94cbecb5e43e98f656294d1183f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3565 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steven\\anaconda3\\envs\\dl_frame\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 29\u001b[0m\n\u001b[0;32m     20\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Necessary to pad predictions and labels for being gathered\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# predictions_pad = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# batch_labels = accelerator.pad_across_processes(batch[\"labels\"], dim=1, pad_index=-100)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# true_predictions, true_labels = postprocess(prediction, references)\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     metric\u001b[38;5;241m.\u001b[39madd_batch(predictions\u001b[38;5;241m=\u001b[39mpredictions, references\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     30\u001b[0m     progress_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     32\u001b[0m eval_metric \u001b[38;5;241m=\u001b[39m metric\u001b[38;5;241m.\u001b[39mcompute()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl_frame\\Lib\\site-packages\\evaluate\\module.py:937\u001b[0m, in \u001b[0;36mCombinedEvaluations.add_batch\u001b[1;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[0;32m    935\u001b[0m batch \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m\"\u001b[39m: predictions, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreferences\u001b[39m\u001b[38;5;124m\"\u001b[39m: references, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m    936\u001b[0m batch \u001b[38;5;241m=\u001b[39m {input_name: batch[input_name] \u001b[38;5;28;01mfor\u001b[39;00m input_name \u001b[38;5;129;01min\u001b[39;00m evaluation_module\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[1;32m--> 937\u001b[0m evaluation_module\u001b[38;5;241m.\u001b[39madd_batch(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl_frame\\Lib\\site-packages\\evaluate\\module.py:515\u001b[0m, in \u001b[0;36mEvaluationModule.add_batch\u001b[1;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(column) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    514\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enforce_nested_string_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_feature_format[key], column[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m--> 515\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_feature_format\u001b[38;5;241m.\u001b[39mencode_batch(batch)\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39mwrite_batch(batch)\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl_frame\\Lib\\site-packages\\datasets\\features\\features.py:1956\u001b[0m, in \u001b[0;36mFeatures.encode_batch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m   1954\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn mismatch between batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mset\u001b[39m(batch)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and features \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1955\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, column \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m-> 1956\u001b[0m     column \u001b[38;5;241m=\u001b[39m cast_to_python_objects(column)\n\u001b[0;32m   1957\u001b[0m     encoded_batch[key] \u001b[38;5;241m=\u001b[39m [encode_nested_example(\u001b[38;5;28mself\u001b[39m[key], obj, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m column]\n\u001b[0;32m   1958\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoded_batch\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl_frame\\Lib\\site-packages\\datasets\\features\\features.py:447\u001b[0m, in \u001b[0;36mcast_to_python_objects\u001b[1;34m(obj, only_1d_for_numpy, optimize_list_casting)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcast_to_python_objects\u001b[39m(obj: Any, only_1d_for_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, optimize_list_casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    428\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;124;03m    Cast numpy/pytorch/tensorflow/pandas objects to python lists.\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;124;03m    It works recursively.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;124;03m        casted_obj: the casted object\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cast_to_python_objects(\n\u001b[0;32m    448\u001b[0m         obj, only_1d_for_numpy\u001b[38;5;241m=\u001b[39monly_1d_for_numpy, optimize_list_casting\u001b[38;5;241m=\u001b[39moptimize_list_casting\n\u001b[0;32m    449\u001b[0m     )[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl_frame\\Lib\\site-packages\\datasets\\features\\features.py:317\u001b[0m, in \u001b[0;36m_cast_to_python_objects\u001b[1;34m(obj, only_1d_for_numpy, optimize_list_casting)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()[()], \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m only_1d_for_numpy \u001b[38;5;129;01mor\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    320\u001b[0m         [\n\u001b[0;32m    321\u001b[0m             _cast_to_python_objects(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    327\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(len(test_dataloader)))\n",
    "metric = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "Overall_eval = {'accuracy':[], 'f1':[], 'precision':[], 'recall':[]}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model = model.to(device)\n",
    "\n",
    "model.eval()\n",
    "for batch in test_dataloader:\n",
    "    batch = batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    predictions = outputs.logits.argmax(dim=-1)\n",
    "\n",
    "    # Necessary to pad predictions and labels for being gathered\n",
    "    # predictions_pad = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
    "    # batch_labels = accelerator.pad_across_processes(batch[\"labels\"], dim=1, pad_index=-100)\n",
    "    \n",
    "    # predictions, references = accelerator.gather_for_metrics((predictions, batch[\"labels\"]))\n",
    "\n",
    "    # true_predictions, true_labels = postprocess(prediction, references)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    progress_bar.update(1)\n",
    "\n",
    "eval_metric = metric.compute()\n",
    "# accelerator.print(\n",
    "#     f\"epoch {epoch}:\", eval_metric\n",
    "# )\n",
    "print(eval_metric)\n",
    "for key, value in eval_metric.items():\n",
    "    Overall_eval[key].append(round(value, 3))\n",
    "print(Overall_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
